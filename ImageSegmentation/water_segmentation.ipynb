{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBa/gVWG1Y1dvVESN2MNn1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pengyu-gis/MyDeepLearing/blob/main/ImageSegmentation/water_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect GPU"
      ],
      "metadata": {
        "id": "ZNzDbRdbS0PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "rosGH7ywQBmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Dataset"
      ],
      "metadata": {
        "id": "OFQJex7yBadF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# The URL of the dataset\n",
        "url = ''\n",
        "# Sending a GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Open a file with write-binary mode, which allows writing data to the file in binary format.\n",
        "    # This is important for non-text files, such as a ZIP.\n",
        "    with open(\"Track1.zip\", \"wb\") as file:\n",
        "        file.write(response.content)\n",
        "    print(\"Download successful!\")\n",
        "else:\n",
        "    print(\"Error downloading the file:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywVA_0ZVViL3",
        "outputId": "7cc5b8af-56e4-40f9-fce0-7825bc70d63a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/Track1.zip -d /content/Water_Bodies_Dataset/"
      ],
      "metadata": {
        "id": "iooc7-nOXXlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "qWdeVgwCgu25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "import rasterio\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "fbBJ12qLf8fj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image_tif(path):\n",
        "    with rasterio.open(path) as src:\n",
        "        # Assuming the first three bands are RGB; adjust as necessary for your data\n",
        "        image = src.read([1, 2, 3])  # Read only the first three bands\n",
        "        # Convert from (C, H, W) to (H, W, C) for PIL compatibility\n",
        "        image = np.moveaxis(image, 0, -1)\n",
        "        # Ensure image is in uint8 format for PIL\n",
        "        image = np.clip(image, 0, 255).astype(np.uint8)\n",
        "    return image\n",
        "\n",
        "class WaterBodiesDataset(Dataset):\n",
        "    def __init__(self, images_folder, masks_folder, image_transform=None, mask_transform=None):\n",
        "        self.images_folder = images_folder\n",
        "        self.masks_folder = masks_folder\n",
        "        self.image_transform = image_transform\n",
        "        self.mask_transform = mask_transform\n",
        "        self.images = [img.split('/')[-1] for img in glob.glob(images_folder + \"/*.tif\")]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.images[idx]\n",
        "        image_path = os.path.join(self.images_folder, image_name)\n",
        "        mask_path = os.path.join(self.masks_folder, image_name.replace('.tif', '.png'))\n",
        "\n",
        "        image = read_image_tif(image_path)  # Assuming read_image_tif returns a numpy array\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        if self.image_transform:\n",
        "            image = self.image_transform(image)\n",
        "\n",
        "        if self.mask_transform:\n",
        "            mask = self.mask_transform(mask)\n",
        "        else:\n",
        "            mask = transforms.ToTensor()(mask)  # Default transform for masks\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# Define separate transforms for images and masks\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Add more transforms as needed, but no normalization\n",
        "])\n",
        "\n",
        "# Initialize Dataset with separate transforms\n",
        "train_dataset = WaterBodiesDataset(images_folder='/content/Water_Bodies_Dataset/Track1/train/images',\n",
        "                                   masks_folder='/content/Water_Bodies_Dataset/Track1/train/labels',\n",
        "                                   image_transform=image_transform,\n",
        "                                   mask_transform=mask_transform)\n"
      ],
      "metadata": {
        "id": "tX3FjaXkhc9J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n"
      ],
      "metadata": {
        "id": "Cj8A3B0OgHXa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.segmentation.deeplabv3_resnet101(pretrained=True)\n",
        "model.classifier[4] = nn.Conv2d(256, 1, kernel_size=(1, 1))  # Assuming binary segmentation\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoQakHlTgOIM",
        "outputId": "d75416ce-7c25-442c-9065-d4253e7e1b35"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet101_coco-586e9e4e.pth\n",
            "100%|██████████| 233M/233M [00:03<00:00, 64.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 7\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images, masks in train_loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)['out']\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "id": "F0g9aSFogPrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save the model"
      ],
      "metadata": {
        "id": "7rGBY3o7VZ25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model's state dictionary\n",
        "torch.save(model.state_dict(), 'path_to_save_model/model_state_dict.pth')\n",
        "\n",
        "# Optionally, save the entire model\n",
        "torch.save(model, 'path_to_save_model/entire_model.pth')\n"
      ],
      "metadata": {
        "id": "Kr_q-W1bVYcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating the F1 Score\n"
      ],
      "metadata": {
        "id": "yxpgDZyKVeNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have a DataLoader for your validation set called `val_loader`\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Containers for true labels and predictions\n",
        "true_labels = []\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, masks in val_loader:\n",
        "        images = images.to(device)\n",
        "        output = model(images)['out']  # Adjust depending on your model's output\n",
        "        output = torch.sigmoid(output)  # Apply sigmoid to get probabilities\n",
        "        output = (output > 0.5).int()  # Threshold probabilities to get binary mask\n",
        "\n",
        "        # Flatten the masks and outputs to compute F1 score per image\n",
        "        true_labels.extend(masks.cpu().view(-1).numpy())\n",
        "        predictions.extend(output.cpu().view(-1).numpy())\n",
        "\n",
        "# Compute F1 score\n",
        "f1 = f1_score(true_labels, predictions, average='binary')  # or 'macro' if multi-class segmentation\n",
        "print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "77_YI6iAgPzu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}